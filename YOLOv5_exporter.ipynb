{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8caa69d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image_show(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eefb95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_predictions(predictions, image_path, iamge_name):\n",
    "#     # Load the image\n",
    "#     image = cv2.imread(image_path)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     # Create a figure and axis\n",
    "#     fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "#     ax.imshow(image)\n",
    "\n",
    "#     # Plot each prediction\n",
    "#     for pred in predictions:\n",
    "#         label, score, bbox = pred  # unpack tuple\n",
    "\n",
    "#         # Draw bounding box\n",
    "#         rect = plt.Rectangle((bbox[0], bbox[1]), bbox[2] - bbox[0], bbox[3] - bbox[1],\n",
    "#                              linewidth=2, edgecolor='red', facecolor='none')\n",
    "#         ax.add_patch(rect)\n",
    "\n",
    "#         # Add label and score\n",
    "#         ax.text(bbox[0], bbox[1] - 10, f'{label}: {score:.2f}', color='red', fontsize=12, \n",
    "#                 bbox=dict(facecolor='white', alpha=0.5, edgecolor='none'))\n",
    "\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "#     fig.savefig(os.path.join('/ExDark-Object-Detection/output', image_name))\n",
    "#     plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c68db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def detect_image_yolov5(image_path, model_path='/ExDark-Object-Detection/models/YOLOv5.pt'):\n",
    "    # Load YOLOv5 model\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path, device=device)\n",
    "    model.eval()\n",
    "\n",
    "    # Đọc ảnh bằng OpenCV\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Không thể đọc ảnh từ đường dẫn: {image_path}\")\n",
    "\n",
    "    # Convert BGR -> RGB vì OpenCV dùng BGR, YOLOv5 dùng RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Dự đoán\n",
    "    results = model(img_rgb)\n",
    "\n",
    "    # Kết quả dạng pandas DataFrame\n",
    "    df = results.pandas().xyxy[0]  # bounding boxes theo dạng (x1, y1, x2, y2)\n",
    "\n",
    "    output = []\n",
    "    for _, row in df.iterrows():\n",
    "        label = row['name']\n",
    "        conf = float(row['confidence'])\n",
    "        bbox = (int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax']))\n",
    "        output.append((label, conf, bbox))\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77c7d157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Using cache found in C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-6-4 Python-3.12.4 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A1000 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 232 layers, 7257306 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\DELL Pre 7670/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    }
   ],
   "source": [
    "# Use the default YOLOv5s model if custom model is not available\n",
    "output = {}\n",
    "\n",
    "# Get all of the images in the input directory\n",
    "input_dir = '/ExDark-Object-Detection/input'\n",
    "\n",
    "if not os.path.exists(input_dir):\n",
    "    raise ValueError(f\"Input directory does not exist: {input_dir}\")\n",
    "input_images = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "if not input_images:\n",
    "    raise ValueError(f\"No images found in input directory: {input_dir}\")\n",
    "\n",
    "for image_name in input_images:\n",
    "    image_path = os.path.join(input_dir, image_name)\n",
    "    test_image_show(image_path)  # Show the image\n",
    "    pred = detect_image_yolov5(image_path)  # Get predictions\n",
    "    output[image_name] = pred  # Store predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7071cc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for special_test.jpg:\n",
      "Predictions for test_1.jpg:\n",
      "  Label: People, Confidence: 0.90, BBox: (81, 107, 102, 163)\n",
      "  Label: People, Confidence: 0.86, BBox: (124, 106, 148, 160)\n",
      "Predictions for test_10.jpg:\n",
      "  Label: People, Confidence: 0.90, BBox: (481, 87, 601, 266)\n",
      "Predictions for test_11.jpg:\n",
      "  Label: Bus, Confidence: 0.94, BBox: (1204, 457, 2263, 1766)\n",
      "  Label: Car, Confidence: 0.63, BBox: (394, 1213, 678, 1371)\n",
      "  Label: Car, Confidence: 0.53, BBox: (955, 1141, 1217, 1308)\n",
      "Predictions for test_13.jpg:\n",
      "  Label: People, Confidence: 0.67, BBox: (381, 197, 526, 337)\n",
      "  Label: People, Confidence: 0.66, BBox: (119, 119, 194, 248)\n",
      "  Label: People, Confidence: 0.44, BBox: (116, 114, 276, 261)\n",
      "Predictions for test_14.jpg:\n",
      "Predictions for test_15.jpg:\n",
      "Predictions for test_16.jpg:\n",
      "  Label: People, Confidence: 0.69, BBox: (129, 62, 480, 470)\n",
      "Predictions for test_17.jpg:\n",
      "  Label: Motorbike, Confidence: 0.60, BBox: (488, 1272, 3246, 5408)\n",
      "  Label: People, Confidence: 0.27, BBox: (892, 944, 2839, 5408)\n",
      "Predictions for test_18.jpg:\n",
      "  Label: Motorbike, Confidence: 0.91, BBox: (347, 182, 489, 336)\n",
      "Predictions for test_2.jpg:\n",
      "  Label: Car, Confidence: 0.91, BBox: (229, 448, 362, 551)\n",
      "  Label: Car, Confidence: 0.88, BBox: (490, 447, 593, 521)\n",
      "  Label: Car, Confidence: 0.84, BBox: (611, 436, 692, 509)\n",
      "  Label: People, Confidence: 0.81, BBox: (402, 448, 614, 970)\n",
      "  Label: Car, Confidence: 0.80, BBox: (566, 446, 631, 517)\n",
      "  Label: Car, Confidence: 0.77, BBox: (379, 452, 495, 533)\n",
      "  Label: People, Confidence: 0.36, BBox: (121, 431, 180, 547)\n",
      "  Label: Car, Confidence: 0.28, BBox: (687, 449, 730, 485)\n",
      "  Label: Car, Confidence: 0.25, BBox: (650, 441, 720, 491)\n",
      "Predictions for test_3.jpg:\n",
      "  Label: People, Confidence: 0.62, BBox: (103, 25, 128, 75)\n",
      "  Label: Bicycle, Confidence: 0.54, BBox: (0, 12, 91, 165)\n",
      "  Label: People, Confidence: 0.39, BBox: (33, 2, 84, 141)\n",
      "Predictions for test_4.jpg:\n",
      "Predictions for test_5.jpg:\n",
      "  Label: Car, Confidence: 0.92, BBox: (777, 762, 1834, 1270)\n",
      "Predictions for test_6.jpg:\n",
      "  Label: People, Confidence: 0.27, BBox: (956, 879, 1098, 1193)\n",
      "Predictions for test_7.jpg:\n",
      "  Label: Car, Confidence: 0.54, BBox: (93, 67, 132, 85)\n",
      "Predictions for test_8.jpg:\n",
      "Predictions for test_9.jpg:\n",
      "  Label: People, Confidence: 0.79, BBox: (114, 106, 129, 125)\n"
     ]
    }
   ],
   "source": [
    "for image_name, predictions in output.items():\n",
    "    print(f\"Predictions for {image_name}:\")\n",
    "    for label, conf, bbox in predictions:\n",
    "        print(f\"  Label: {label}, Confidence: {conf:.2f}, BBox: {bbox}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c285ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'special_test.jpg': [], 'test_1.jpg': [('People', 0.9019312858581543, (81, 107, 102, 163)), ('People', 0.860504150390625, (124, 106, 148, 160))], 'test_10.jpg': [('People', 0.8970347046852112, (481, 87, 601, 266))], 'test_11.jpg': [('Bus', 0.9393107891082764, (1204, 457, 2263, 1766)), ('Car', 0.6256062388420105, (394, 1213, 678, 1371)), ('Car', 0.5270803570747375, (955, 1141, 1217, 1308))], 'test_13.jpg': [('People', 0.670373260974884, (381, 197, 526, 337)), ('People', 0.6604030132293701, (119, 119, 194, 248)), ('People', 0.4448811709880829, (116, 114, 276, 261))], 'test_14.jpg': [], 'test_15.jpg': [], 'test_16.jpg': [('People', 0.6936938166618347, (129, 62, 480, 470))], 'test_17.jpg': [('Motorbike', 0.6047858595848083, (488, 1272, 3246, 5408)), ('People', 0.26755160093307495, (892, 944, 2839, 5408))], 'test_18.jpg': [('Motorbike', 0.9067729115486145, (347, 182, 489, 336))], 'test_2.jpg': [('Car', 0.9115651249885559, (229, 448, 362, 551)), ('Car', 0.8812650442123413, (490, 447, 593, 521)), ('Car', 0.8443943858146667, (611, 436, 692, 509)), ('People', 0.8051103353500366, (402, 448, 614, 970)), ('Car', 0.7979825735092163, (566, 446, 631, 517)), ('Car', 0.7658812403678894, (379, 452, 495, 533)), ('People', 0.36156365275382996, (121, 431, 180, 547)), ('Car', 0.2831708788871765, (687, 449, 730, 485)), ('Car', 0.25104260444641113, (650, 441, 720, 491))], 'test_3.jpg': [('People', 0.615678071975708, (103, 25, 128, 75)), ('Bicycle', 0.5417863130569458, (0, 12, 91, 165)), ('People', 0.3908799886703491, (33, 2, 84, 141))], 'test_4.jpg': [], 'test_5.jpg': [('Car', 0.9175679683685303, (777, 762, 1834, 1270))], 'test_6.jpg': [('People', 0.2697101831436157, (956, 879, 1098, 1193))], 'test_7.jpg': [('Car', 0.5361272096633911, (93, 67, 132, 85))], 'test_8.jpg': [], 'test_9.jpg': [('People', 0.7931485176086426, (114, 106, 129, 125))]}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {'special_test.jpg': [], 'test_1.jpg': [('People', 0.9019312858581543, (81, 107, 102, 163)), ('People', 0.860504150390625, (124, 106, 148, 160))], 'test_10.jpg': [('People', 0.8970347046852112, (481, 87, 601, 266))], 'test_11.jpg': [('Bus', 0.9393107891082764, (1204, 457, 2263, 1766)), ('Car', 0.6256062388420105, (394, 1213, 678, 1371)), ('Car', 0.5270803570747375, (955, 1141, 1217, 1308))], 'test_13.jpg': [('People', 0.670373260974884, (381, 197, 526, 337)), ('People', 0.6604030132293701, (119, 119, 194, 248)), ('People', 0.4448811709880829, (116, 114, 276, 261))], 'test_14.jpg': [], 'test_15.jpg': [], 'test_16.jpg': [('People', 0.6936938166618347, (129, 62, 480, 470))], 'test_17.jpg': [('Motorbike', 0.6047858595848083, (488, 1272, 3246, 5408)), ('People', 0.26755160093307495, (892, 944, 2839, 5408))], 'test_18.jpg': [('Motorbike', 0.9067729115486145, (347, 182, 489, 336))], 'test_2.jpg': [('Car', 0.9115651249885559, (229, 448, 362, 551)), ('Car', 0.8812650442123413, (490, 447, 593, 521)), ('Car', 0.8443943858146667, (611, 436, 692, 509)), ('People', 0.8051103353500366, (402, 448, 614, 970)), ('Car', 0.7979825735092163, (566, 446, 631, 517)), ('Car', 0.7658812403678894, (379, 452, 495, 533)), ('People', 0.36156365275382996, (121, 431, 180, 547)), ('Car', 0.2831708788871765, (687, 449, 730, 485)), ('Car', 0.25104260444641113, (650, 441, 720, 491))], 'test_3.jpg': [('People', 0.615678071975708, (103, 25, 128, 75)), ('Bicycle', 0.5417863130569458, (0, 12, 91, 165)), ('People', 0.3908799886703491, (33, 2, 84, 141))], 'test_4.jpg': [], 'test_5.jpg': [('Car', 0.9175679683685303, (777, 762, 1834, 1270))], 'test_6.jpg': [('People', 0.2697101831436157, (956, 879, 1098, 1193))], 'test_7.jpg': [('Car', 0.5361272096633911, (93, 67, 132, 85))], 'test_8.jpg': [], 'test_9.jpg': [('People', 0.7931485176086426, (114, 106, 129, 125))]}\n",
    "input_path =  '/ExDark-Object-Detection/input'\n",
    "output_path = '/ExDark-Object-Detection/output/YOLOv5'\n",
    "\n",
    "def plot_predictions(output, input_path, output_path):\n",
    "    for image_name, predictions in output.items():\n",
    "        # Load the image\n",
    "        image_path = os.path.join(input_path, image_name)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image {image_name} does not exist in {input_path}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        image = plt.imread(image_path)\n",
    "        \n",
    "        # Create a figure and axis\n",
    "        fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "        ax.imshow(image)\n",
    "\n",
    "        # Plot each prediction\n",
    "        for label, score, bbox in predictions:\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            \n",
    "            # Draw rectangle around the object\n",
    "            rect = plt.Rectangle((x1, y1), width, height, linewidth=2, edgecolor='red', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # Add label and score\n",
    "            ax.text(x1, y1 - 10, f\"{label} ({score:.2f})\", color='white', fontsize=12)\n",
    "\n",
    "        # Set title and show plot\n",
    "        ax.set_title(f\"Predictions for {image_name}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Save the plot to output directory\n",
    "        output_image_path = os.path.join(output_path, f\"predicted_{image_name}\")\n",
    "        plt.savefig(output_image_path)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        print(f\"Saved predictions for {image_name} to {output_image_path}\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    # Plot predictions\n",
    "    plot_predictions(output, input_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
